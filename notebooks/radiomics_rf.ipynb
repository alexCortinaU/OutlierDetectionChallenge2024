{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, cohen_kappa_score, precision_score, recall_score\n",
    "\n",
    "from pathlib import Path\n",
    "this_path = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'img_name', 'label_name', 'label',\n",
       "       'original_shape_Elongation', 'original_shape_Flatness',\n",
       "       'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength',\n",
       "       'original_shape_Maximum2DDiameterColumn',\n",
       "       'original_shape_Maximum2DDiameterRow',\n",
       "       'original_shape_Maximum2DDiameterSlice',\n",
       "       'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume',\n",
       "       'original_shape_MinorAxisLength', 'original_shape_Sphericity',\n",
       "       'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio',\n",
       "       'original_shape_VoxelVolume', 'original_firstorder_10Percentile',\n",
       "       'original_firstorder_90Percentile', 'original_firstorder_Energy',\n",
       "       'original_firstorder_Entropy', 'original_firstorder_InterquartileRange',\n",
       "       'original_firstorder_Kurtosis', 'original_firstorder_Maximum',\n",
       "       'original_firstorder_MeanAbsoluteDeviation', 'original_firstorder_Mean',\n",
       "       'original_firstorder_Median', 'original_firstorder_Minimum',\n",
       "       'original_firstorder_Range',\n",
       "       'original_firstorder_RobustMeanAbsoluteDeviation',\n",
       "       'original_firstorder_RootMeanSquared', 'original_firstorder_Skewness',\n",
       "       'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity',\n",
       "       'original_firstorder_Variance', 'original_glcm_Autocorrelation',\n",
       "       'original_glcm_JointAverage', 'original_glcm_ClusterProminence',\n",
       "       'original_glcm_ClusterShade', 'original_glcm_ClusterTendency',\n",
       "       'original_glcm_Contrast', 'original_glcm_Correlation',\n",
       "       'original_glcm_DifferenceAverage', 'original_glcm_DifferenceEntropy',\n",
       "       'original_glcm_DifferenceVariance', 'original_glcm_JointEnergy',\n",
       "       'original_glcm_JointEntropy', 'original_glcm_Imc1',\n",
       "       'original_glcm_Imc2', 'original_glcm_Idm', 'original_glcm_Idmn',\n",
       "       'original_glcm_Id', 'original_glcm_Idn',\n",
       "       'original_glcm_InverseVariance', 'original_glcm_MaximumProbability',\n",
       "       'original_glcm_SumEntropy', 'original_glcm_SumSquares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(this_path.parent / 'radiomics_features.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------shape --------- features \n",
      "\n",
      "Number of features: 14\n",
      "label\n",
      "1    1638\n",
      "0     546\n",
      "Name: count, dtype: int64\n",
      "Data shape: ((2184, 14), (2184,))\n",
      "\n",
      " Metrics 5-fold crossv: \n",
      "\n",
      "accuracy: 0.82 (+/- 0.02)\n",
      "f1: 0.81 (+/- 0.03)\n",
      "cohen_kappa: 0.46 (+/- 0.05)\n",
      "precision: 0.81 (+/- 0.03)\n",
      "recall: 0.82 (+/- 0.02)\n",
      "\n",
      " -------------glcm --------- features \n",
      "\n",
      "Number of features: 22\n",
      "label\n",
      "1    1638\n",
      "0     546\n",
      "Name: count, dtype: int64\n",
      "Data shape: ((2184, 22), (2184,))\n",
      "\n",
      " Metrics 5-fold crossv: \n",
      "\n",
      "accuracy: 0.71 (+/- 0.03)\n",
      "f1: 0.63 (+/- 0.05)\n",
      "cohen_kappa: -0.06 (+/- 0.02)\n",
      "precision: 0.57 (+/- 0.06)\n",
      "recall: 0.71 (+/- 0.03)\n",
      "\n",
      " -------------firstorder --------- features \n",
      "\n",
      "Number of features: 18\n",
      "label\n",
      "1    1638\n",
      "0     546\n",
      "Name: count, dtype: int64\n",
      "Data shape: ((2184, 18), (2184,))\n",
      "\n",
      " Metrics 5-fold crossv: \n",
      "\n",
      "accuracy: 0.71 (+/- 0.03)\n",
      "f1: 0.63 (+/- 0.05)\n",
      "cohen_kappa: -0.06 (+/- 0.02)\n",
      "precision: 0.57 (+/- 0.06)\n",
      "recall: 0.71 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "for feat_type in ['shape', 'glcm', 'firstorder']:\n",
    "    print(f'\\n -------------{feat_type} --------- features \\n')\n",
    "    # feat_type = 'shape' # glcm, firstorder\n",
    "    data = pd.read_csv(this_path.parent / 'radiomics_features.csv')\n",
    "    X = data.drop(columns=['sample_id', 'img_name', 'label_name', 'label'])\n",
    "    filter_col = [col for col in X.columns if feat_type in col]\n",
    "    print(f'Number of features: {len(filter_col)}')\n",
    "    X = X[filter_col]\n",
    "    # binarize the labels\n",
    "    data['label'] = data['label'].map({'normal': 0,\n",
    "                                    'warp': 1,\n",
    "                                    'sphere_water': 1,\n",
    "                                    'sphere_mean': 1,})\n",
    "    y = data['label']\n",
    "    print(y.value_counts())\n",
    "    print(f'Data shape: {X.shape, y.shape}')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=500,\n",
    "                                              random_state=42,\n",
    "                                              class_weight='balanced'))\n",
    "        # ('classifier', svm.SVC(kernel='linear', C=1, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # 5fold cross validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_validate(pipeline, X, y, cv=kf, \n",
    "                            scoring={\n",
    "                                'accuracy': make_scorer(accuracy_score),\n",
    "                                'f1': make_scorer(f1_score, average='weighted'),\n",
    "                                'cohen_kappa': make_scorer(cohen_kappa_score),\n",
    "                                'precision': make_scorer(precision_score, average='weighted'),\n",
    "                                'recall': make_scorer(recall_score, average='weighted')\n",
    "                            }, n_jobs=16)\n",
    "    print(f'\\n Metrics 5-fold crossv: \\n')\n",
    "    # Calculate and print the mean and standard deviation for each metric\n",
    "    for metric in scores.keys():\n",
    "        if metric.startswith('test_'):  # Filter out the test scores\n",
    "            mean_score = np.mean(scores[metric])\n",
    "            std_score = np.std(scores[metric])\n",
    "            print(f'{metric[5:]}: {mean_score:.2f} (+/- {std_score:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 54\n",
      "label\n",
      "1    1638\n",
      "0     546\n",
      "Name: count, dtype: int64\n",
      "Data shape: ((2184, 54), (2184,))\n",
      "\n",
      " Metrics 5-fold crossv: \n",
      "\n",
      "accuracy: 0.79 (+/- 0.03)\n",
      "f1: 0.76 (+/- 0.04)\n",
      "cohen_kappa: 0.33 (+/- 0.07)\n",
      "precision: 0.77 (+/- 0.03)\n",
      "recall: 0.79 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# feat_type = 'shape' # glcm, firstorder\n",
    "data = pd.read_csv(this_path.parent / 'radiomics_features.csv')\n",
    "X = data.drop(columns=['sample_id', 'img_name', 'label_name', 'label'])\n",
    "print(f'Number of features: {len(X.columns)}')\n",
    "# binarize the labels\n",
    "data['label'] = data['label'].map({'normal': 0,\n",
    "                                'warp': 1,\n",
    "                                'sphere_water': 1,\n",
    "                                'sphere_mean': 1,})\n",
    "y = data['label']\n",
    "print(y.value_counts())\n",
    "print(f'Data shape: {X.shape, y.shape}')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=500,\n",
    "                                              random_state=42,\n",
    "                                              class_weight='balanced'))\n",
    "    # ('classifier', svm.SVC(kernel='linear', C=1, random_state=42))\n",
    "])\n",
    "\n",
    "# 5fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_validate(pipeline, X, y, cv=kf, \n",
    "                        scoring={\n",
    "                            'accuracy': make_scorer(accuracy_score),\n",
    "                            'f1': make_scorer(f1_score, average='weighted'),\n",
    "                            'cohen_kappa': make_scorer(cohen_kappa_score),\n",
    "                            'precision': make_scorer(precision_score, average='weighted'),\n",
    "                            'recall': make_scorer(recall_score, average='weighted')\n",
    "                        }, n_jobs=16)\n",
    "print(f'\\n Metrics 5-fold crossv: \\n')\n",
    "# Calculate and print the mean and standard deviation for each metric\n",
    "for metric in scores.keys():\n",
    "    if metric.startswith('test_'):  # Filter out the test scores\n",
    "        mean_score = np.mean(scores[metric])\n",
    "        std_score = np.std(scores[metric])\n",
    "        print(f'{metric[5:]}: {mean_score:.2f} (+/- {std_score:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14\n",
      "label\n",
      "1    1638\n",
      "0     546\n",
      "Name: count, dtype: int64\n",
      "Data shape: ((2184, 14), (2184,))\n",
      "Number of features: 14\n",
      "pred_label\n",
      "1    365\n",
      "0    182\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3058240/3984046669.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df['pred_label'] = y_test\n"
     ]
    }
   ],
   "source": [
    "# Now let´s train the model with all the data\n",
    "\n",
    "data = pd.read_csv(this_path.parent / 'radiomics_features.csv')\n",
    "X = data.drop(columns=['sample_id', 'img_name', 'label_name', 'label'])\n",
    "filter_col = [col for col in X.columns if 'shape' in col]\n",
    "print(f'Number of features: {len(filter_col)}')\n",
    "X = X[filter_col]\n",
    "# binarize the labels\n",
    "data['label'] = data['label'].map({'normal': 0,\n",
    "                                'warp': 1,\n",
    "                                'sphere_water': 1,\n",
    "                                'sphere_mean': 1,})\n",
    "y = data['label']\n",
    "print(y.value_counts())\n",
    "print(f'Data shape: {X.shape, y.shape}')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=500,\n",
    "                                            random_state=42,\n",
    "                                            class_weight='balanced'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "# import joblib\n",
    "# joblib.dump(pipeline, 'rf_shape_model.pkl')\n",
    "# print('Model saved to disk')\n",
    "\n",
    "# and perform the prediction with the test data\n",
    "data = pd.read_csv(this_path.parent / 'test_radiomics_features.csv')\n",
    "X = data.drop(columns=['sample_id', 'img_name', 'label_name'])\n",
    "filter_col = [col for col in X.columns if 'shape' in col]\n",
    "print(f'Number of features: {len(filter_col)}')\n",
    "X_test = X[filter_col]\n",
    "y_test = pipeline.predict(X_test)\n",
    "# save the results\n",
    "results_df = data[['sample_id', 'img_name']]\n",
    "results_df['pred_label'] = y_test\n",
    "print(results_df['pred_label'].value_counts())\n",
    "# results.to_csv(this_path.parent / 'radiomics_results/results_shape.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0538</td>\n",
       "      <td>sample_0538_crop.nii.gz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_0824</td>\n",
       "      <td>sample_0824_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_0813</td>\n",
       "      <td>sample_0813_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_0693</td>\n",
       "      <td>sample_0693_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_0615</td>\n",
       "      <td>sample_0615_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>sample_0277</td>\n",
       "      <td>sample_0277_crop.nii.gz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>sample_0566</td>\n",
       "      <td>sample_0566_crop.nii.gz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>sample_0458</td>\n",
       "      <td>sample_0458_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>sample_0765</td>\n",
       "      <td>sample_0765_crop.nii.gz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>sample_0410</td>\n",
       "      <td>sample_0410_crop.nii.gz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id                 img_name  pred_label\n",
       "0    sample_0538  sample_0538_crop.nii.gz           0\n",
       "1    sample_0824  sample_0824_crop.nii.gz           1\n",
       "2    sample_0813  sample_0813_crop.nii.gz           1\n",
       "3    sample_0693  sample_0693_crop.nii.gz           1\n",
       "4    sample_0615  sample_0615_crop.nii.gz           1\n",
       "..           ...                      ...         ...\n",
       "542  sample_0277  sample_0277_crop.nii.gz           0\n",
       "543  sample_0566  sample_0566_crop.nii.gz           0\n",
       "544  sample_0458  sample_0458_crop.nii.gz           1\n",
       "545  sample_0765  sample_0765_crop.nii.gz           1\n",
       "546  sample_0410  sample_0410_crop.nii.gz           0\n",
       "\n",
       "[547 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n"
     ]
    }
   ],
   "source": [
    "test_200 = pd.read_csv('/home/alejandrocu/OutlierDetectionChallenge2024/challenge_results/test_files_200.txt', header=None)\n",
    "test_set_path = Path(\"/media/7tb_encrypted/od_chall/dataset/challenge_data/test\")\n",
    "# (test_set_path/'crop').exists()\n",
    "test_set_files = list((test_set_path/'crops').glob('*crop.nii.gz'))\n",
    "test_set_files = [f.name.split('_crop')[0] for f in test_set_files]\n",
    "test_names = test_200[0].str.strip().to_list()\n",
    "print(len(test_set_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "results = []\n",
    "for row in results_df.iterrows():\n",
    "    sample_id = row[1]['sample_id']\n",
    "    # print(sample_id)\n",
    "    # print(row[1]['Predicted'])\n",
    "    if sample_id in test_names:\n",
    "        i += 1\n",
    "        results.append({'scan_id': sample_id, 'outlier': row[1]['pred_label']})\n",
    "        # test_names.remove(sample_id)\n",
    "print(i)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Write results to JSON file\n",
    "with open(this_path.parent / 'radiomics_results/test_results.json', 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
